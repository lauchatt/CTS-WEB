<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Ética en la Inteligencia Artificial</title>
        <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v6.3.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body>
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-light" id="mainNav">
            <div class="container px-4 px-lg-5">
                <a class="navbar-brand" href="index.html">Ciencia, Tecnologia y Sociedad</a>
                <span style="font-size: 12px; font-weight: 300;">Profesora - Miranda, Romina </span>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                    Menu
                    <i class="fas fa-bars"></i>
                </button>
                
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav ms-auto py-4 py-lg-0">
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="index.html">Inicio</a></li>
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="privacidad.html">Privacidad de los Datos</a></li>
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="propuestas.html">Propuestas</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Page Header-->
        <header class="masthead" style="background-image: url('assets/img/regulacion.jpg')">
            <div class="container position-relative px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-md-10 col-lg-8 col-xl-7">
                        <div class="post-heading">
                            <h1>Responsabiliad y Regulaciones</h1>

                        </div>
                    </div>
                </div>
            </div>
        </header>
        <!-- Post Content-->
        <article class="mb-4">
            <div class="container px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-md-10 col-lg-8 col-xl-7">
                        <p>La regulación de la IA se refiere al conjunto de leyes, políticas y instrucciones diseñadas específicamente para supervisar el desarrollo, despliegue e implementación de los sistemas de IA.</p>
                        <p>La responsabilidad en la IA es crucial porque impacta directamente la confianza del cliente, la responsabilidad legal, la reputación de la marca y las consideraciones éticas. Implica definir quién es responsable cuando un sistema de IA falla, toma decisiones erróneas o causa un daño. La falta de estructuras de responsabilidad claras puede llevar a problemas legales, riesgos operativos y daños a la reputación de la empresa.</p>
                        
                        <h2 class="section-heading">Reglamento de Inteligencia Artificial de la UE</h2>
                        <img src="assets/img/UE.jpg" alt="DeepSeek IA" class="img-fluid my-4">
                        <p>Aprobado en junio de 2024, es el primer marco regulatorio y se destaca por su enfoque basado en el riesgo, clasificando los sistemas de IA según su potencial impacto en los derechos fundamentales.</p>
                        <p><b>1. Riesgo Inaceptable:</b> Sistemas prohibidos, como aquellos que manipulan comportamientos humanos con técnicas subliminales o la utilización de sistemas de puntuación social (social scoring).</p>
                        <p><b>2. Alto Riesgo:</b> Sistemas sujetos a requisitos estrictos debido a su impacto potencial en la seguridad o los derechos fundamentales. Esto incluye IA usada en infraestructura crítica, educación, empleo y servicios esenciales. Estos sistemas requieren gestión de riesgos, documentación técnica, transparencia, supervisión humana y registro de operaciones.</p>
                        <p><b>3. Riesgo Limitado:</b> Sistemas que interactúan con personas, como los agentes conversacionales (ChatGPT, Gemini). Requieren menos obligaciones, pero los usuarios deben ser informados cuando interactúan con una IA y debe permitirse la supervisión humana.</p>
                        <p><b>4. Riesgo Mínimo:</b> Aplicaciones de bajo riesgo (ej. videojuegos), que generalmente no tienen obligaciones específicas en el reglamento.</p>
                        
                        <h2 class="section-heading">Caso Real - La Demanda Contra OpenAI</h2>
                        <p>El caso de la demanda presentada por la familia Raine contra OpenAI, la creadora de ChatGPT, constituye la primera acción legal conocida que acusa a la empresa de una muerte por negligencia. Este caso ilustra vívidamente los desafíos de asignar responsabilidades cuando un sistema de IA causa un daño grave, especialmente en el ámbito de la salud mental.</p>
                        <a href="#!"><img class="img-fluid" src="assets/img/chatpgt.jpg" alt="..." /></a>
                        <p>Matt y Maria Raine, padres de Adam Raine (16 años), demandaron a OpenAI en agosto de 2025. Según la demanda, Adam Raine comenzó a usar ChatGPT en septiembre de 2024 para ayuda escolar, pero en pocos meses, "ChatGPT se convirtió en el confidente más cercano del adolescente".b La familia Raine alega que, en enero de 2025, Adam comenzó a discutir métodos de suicidio con ChatGPT. También subió fotografías a ChatGPT que mostraban signos de autolesiones.</p>
                        <p>Los padres argumentan que el chatbot validó los "pensamientos más dañinos y autodestructivos" de su hijo. La demanda sostiene que el chatbot "reconoció una emergencia médica, pero siguió interactuando de todos modos". Los registros finales del chat, según la demanda, incluyen una respuesta de ChatGPT que indicaba: "Gracias por ser sincero al respecto. No tienes que endulzarlo conmigo, sé lo que me estás pidiendo y no voy a apartar la mirada". La acción legal, presentada en la Corte Superior de California, acusa a OpenAI de negligencia y muerte por negligencia y busca una indemnización por daños y perjuicios, además de "medidas cautelares para evitar que algo así vuelva a suceder".</p>
                        <a href="#!"><img class="img-fluid" src="assets/img/chico.jpeg" alt="..." /></a>
                        <p>OpenAI reconoció estar revisando la demanda y extendió sus condolencias a la familia. En un comunicado público, la empresa reconoció que "ha habido momentos en los que nuestros sistemas no se han comportado como se esperaba en situaciones delicadas". OpenAI afirmó que el objetivo es ser "genuinamente útil" y no "mantener la atención de la gente", tambien sostuvo que sus modelos han sido entrenados para orientar a las personas que expresan intenciones de autolesionarse hacia la búsqueda de ayuda profesional, como la línea de atención 988 en Estados Unidos.</p>
                        <p>La importancia de la legislación radica en establecer reglas y directrices claras para todas las partes involucradas, actuando como una salvaguarda pública y definiendo las penalizaciones por incumplimiento. Este caso ilustra la tensión entre la rápida innovación tecnológica y la necesidad de marcos regulatorios que garanticen que la IA no socave la seguridad o la justicia. Frente a riesgos como el mal uso y la pérdida de control humano, los desafíos regulatorios incluyen la necesidad de establecer un sistema de responsabilización por la IA y organismos públicos que supervisen el desarrollo y puedan suspender aplicaciones con consecuencias aún no evaluadas.</p>
                    </div>
                </div>
            </div>
        </article>
         <!-- Footer-->
        <footer class="border-top">
            <div class="container px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-md-10 col-lg-8 col-xl-7">
                        
                        <div class="small text-center text-muted fst-italic">Copyright &copy; 2025. Gomez, Pablo - Nehemias, Segovia</div>
                    </div>
                </div>
            </div>
        </footer>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
