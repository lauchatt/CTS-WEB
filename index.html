<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Ética en la Inteligencia Artificial</title>
        <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v6.3.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body>
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-light" id="mainNav">
            <div class="container px-4 px-lg-5">
                <a class="navbar-brand" href="index.html">Ciencia, Tecnologia y Sociedad</a>
                <span style="font-size: 12px; font-weight: 300; color: white;">Profesora - Miranda, Romina </span>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                    Menu
                    <i class="fas fa-bars"></i>
                </button>
                
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav ms-auto py-4 py-lg-0">
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="privacidad.html">Privacidad de los Datos</a></li>
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="responsabilidad.html">Responsabiliad y Regulaciones</a></li>
                        <li class="nav-item"><a class="nav-link px-lg-3 py-3 py-lg-4" href="propuestas.html">Propuestas</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Page Header-->
        <header class="masthead" style="background-image: url('assets/img/box_img.jpg')">
            <div class="container position-relative px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-md-10 col-lg-8 col-xl-7">
                        <div class="site-heading">
                            <h1>Ética en la Inteligencia Artificial</h1>
                            
                            <!-- <span class="subheading">A Blog Theme by Start Bootstrap</span> -->
                        </div>
                    </div>
                </div>
            </div>
        </header>
        <!-- Main Content-->
        <div class="container px-4 px-lg-5">
            <div class="row gx-4 gx-lg-5 justify-content-center">
                <div class="col-md-10 col-lg-8 col-xl-7">
                    <!-- Post preview-->
                    <div class="post-preview">
                        <a >
                            
                            <p class="post-subtitle">A medida que la inteligencia artificial (IA) se integra cada vez más en diversas áreas de nuestras vidas, como la medicina, la gestión financiera eficiente y la educación, nos plantea un número creciente de dilemas éticos. La capacidad de estas tecnologías para influir en aspectos de la vida humana plantea la pregunta de cómo proteger nuestros derechos y asegurarnos que su uso apoya el bienestar colectivo sin causar daños. En este sentido, dos temas son muy importantes: la privacidad de los datos y la responsabilidad, con las regulaciones que deben aplicarse al uso de la IA.</p>
                            <p class="post-subtitle">Por un lado, la privacidad de nuestros datos están en peligro porque los sistemas de IA manejan grandes cantidades de información personal, varias veces sin el consentimiento explícito de las personas o sin controles claros. Por otro lado, la responsabilidad implica definir quién es responsable cuando un sistema de IA falla, toma decisiones erróneas o causa un daño, además de establecer leyes que regulen cómo se diseñan, aplican y supervisan estas tecnologías. La falta de estructuras de responsabilidad claras puede llevar a problemas legales, riesgos operativos y daños a la reputación de la empresa.</p>
                            <P class="post-subtitle">Ambos temas se relacionan porque tratar información personal implica conocer cómo se recolecta, almacena, usa y comparte esa información. Si no existe un conjunto claro de responsabilidades, no es posible garantizar que la privacidad se respete. Para proteger la privacidad, hace falta que alguien sea responsable de justificar por qué ciertos datos fueron recopilados, explicar cómo se van a usary asegurar que no se filtren ni se utilicen para fines no autorizados.</P>
                            <p class="post-subtitle">Esto solo es posible si existen normas y mecanismos de responsabilidad que obliguen a empresas y desarrolladores a rendir cuentas. Por ejemplo, si un sistema de IA toma una decisión discriminatoria porque los datos estaban mal gestionados, debe haber una entidad responsable de ese daño, ya sea el programador, la empresa o el usuario que implementó el sistema.</p>
                        </a>
                        
                    </div>
                    <!-- Divider-->
                    <hr class="my-4" />
                    <!-- Post preview-->
                    <div class="post-preview">
                        <a >
                            <h2 class="post-title">Conclusion </h2>
                            
                        </a>
                        <img src="assets/img/business_img.jpg" alt="DeepSeek IA" class="img-fluid my-4">
                        <p class="post-meta">
                            Como grupo pensamos que la inteligencia artificial puede traer muchos beneficios a la sociedad, pero también genera desafíos que debemos tener en cuenta. Es importante cuidar la privacidad de nuestros datos y saber quién se hace responsable cuando la tecnología se usa mal o causa algún daño. Creemos que todas las personas tienen derecho a decidir qué se hace con su información y que las empresas o instituciones deben ser claras y justas en su uso. La inteligencia artificial debe ayudarnos a mejorar la vida, no a poner en riesgo nuestros derechos. En resumen, el progreso no depende solo de tener máquinas más inteligentes, sino de usarlas con valores, respeto y responsabilidad, para que sirvan al bien de todos.
                        </p>
                    </div>
                    <!-- Divider-->
                    <hr class="my-4" />
                    <!-- Pager-->
                    <div class="d-flex justify-content-end mb-4"><a onclick="abrirPaginas()" title="Cuidado: se abrirán 10 páginas emergentes" class="btn btn-primary text-uppercase" href="#!">Bibliografia →</a></div>
                </div>
            </div>
        </div>
        <!-- Footer-->
        <footer class="border-top">
            <div class="container px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-md-10 col-lg-8 col-xl-7">
                        
                        <div class="small text-center text-muted fst-italic">Copyright &copy; 2025. Gomez, Pablo - Nehemias, Segovia</div>
                    </div>
                </div>
            </div>
        </footer>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
        <script>
function abrirPaginas() {
  const paginas = [
    "https://www.ibm.com/es-es/think/insights/ai-privacy",
    "https://www.dataguard.com/blog/growing-data-privacy-concerns-ai",
    "https://www.infobae.com/america/mundo/2025/02/06/corea-del-sur-bloqueo-el-acceso-a-deepseek-por-sospechas-de-espionaje-y-riesgos-de-filtracion-de-datos-sensibles",
    "https://www.infobae.com/tecno/2025/02/08/deepseek-en-problemas-paises-comienzan-a-prohibir-la-ia-por-filtracion-de-datos-de-usuarios",
    "https://favierduboisspagnolo.com/trabajos-de-doctrina/riesgos-y-regulaciones-de-la-inteligencia-artificial",
    "https://aisigil.com/es/responsabilidad-en-la-ia-quien-responde-cuando-algo-sale-mal",
    "https://www.datacamp.com/es/blog/ai-regulation",
    "https://www.bbc.com/mundo/articles/c30z5lyjzygo"
  ];

  paginas.forEach((url, i) => {
    setTimeout(() => {
      window.open(url, "_blank");
    }, i * 700); // abre cada una con 0.7 segundos de diferencia
  });
}

</script>
    </body>
</html>
